{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 10 - PCA and Dimension Reduction Homework\n",
    "Execute the below code and answer the following questions. __Do NOT commit the csv file!__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "def generate_data():\n",
    "    x, y = make_classification(n_samples=1500, \n",
    "                            n_features = 20,\n",
    "                            n_informative = 8,\n",
    "                            n_redundant = 5,\n",
    "                            n_repeated = 1, \n",
    "                            n_classes = 3,\n",
    "                            weights = (0.5, 0.25, 0.25),\n",
    "                            random_state = 120\n",
    "                            )\n",
    "    colNames = ['var'+str(x) for x in range(20)]\n",
    "    colNames.append('target')\n",
    "\n",
    "    df = pd.DataFrame(np.concatenate((x,y.reshape(-1,1)), axis=1), columns=colNames)\n",
    "    df.to_csv('pca-dataset.csv', index=False)\n",
    "    \n",
    "generate_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var0</th>\n",
       "      <th>var1</th>\n",
       "      <th>var2</th>\n",
       "      <th>var3</th>\n",
       "      <th>var4</th>\n",
       "      <th>var5</th>\n",
       "      <th>var6</th>\n",
       "      <th>var7</th>\n",
       "      <th>var8</th>\n",
       "      <th>var9</th>\n",
       "      <th>...</th>\n",
       "      <th>var11</th>\n",
       "      <th>var12</th>\n",
       "      <th>var13</th>\n",
       "      <th>var14</th>\n",
       "      <th>var15</th>\n",
       "      <th>var16</th>\n",
       "      <th>var17</th>\n",
       "      <th>var18</th>\n",
       "      <th>var19</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.882513</td>\n",
       "      <td>-3.272465</td>\n",
       "      <td>-2.520732</td>\n",
       "      <td>-1.987174</td>\n",
       "      <td>-2.073689</td>\n",
       "      <td>-3.272465</td>\n",
       "      <td>-1.237969</td>\n",
       "      <td>1.690547</td>\n",
       "      <td>-0.211314</td>\n",
       "      <td>-5.753190</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.574979</td>\n",
       "      <td>-1.916275</td>\n",
       "      <td>-5.994075</td>\n",
       "      <td>-3.349615</td>\n",
       "      <td>-0.846193</td>\n",
       "      <td>2.491347</td>\n",
       "      <td>1.360958</td>\n",
       "      <td>-2.892522</td>\n",
       "      <td>-1.377561</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.775242</td>\n",
       "      <td>-1.015994</td>\n",
       "      <td>0.005137</td>\n",
       "      <td>0.057274</td>\n",
       "      <td>0.590205</td>\n",
       "      <td>-1.015994</td>\n",
       "      <td>1.350954</td>\n",
       "      <td>-1.493037</td>\n",
       "      <td>-0.862391</td>\n",
       "      <td>-1.986047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.523760</td>\n",
       "      <td>0.399579</td>\n",
       "      <td>0.088600</td>\n",
       "      <td>0.718606</td>\n",
       "      <td>-1.112030</td>\n",
       "      <td>0.083929</td>\n",
       "      <td>0.606544</td>\n",
       "      <td>-1.376793</td>\n",
       "      <td>1.302641</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.876376</td>\n",
       "      <td>0.220453</td>\n",
       "      <td>3.114224</td>\n",
       "      <td>-1.640025</td>\n",
       "      <td>1.180348</td>\n",
       "      <td>0.220453</td>\n",
       "      <td>0.465102</td>\n",
       "      <td>0.222511</td>\n",
       "      <td>0.880455</td>\n",
       "      <td>2.922315</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.370516</td>\n",
       "      <td>3.585262</td>\n",
       "      <td>-2.168162</td>\n",
       "      <td>2.693429</td>\n",
       "      <td>-0.966636</td>\n",
       "      <td>1.586302</td>\n",
       "      <td>-2.821546</td>\n",
       "      <td>0.482164</td>\n",
       "      <td>0.187404</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.550342</td>\n",
       "      <td>-1.968144</td>\n",
       "      <td>0.077681</td>\n",
       "      <td>-1.887719</td>\n",
       "      <td>1.864445</td>\n",
       "      <td>-1.968144</td>\n",
       "      <td>-0.527958</td>\n",
       "      <td>-0.201467</td>\n",
       "      <td>-0.532649</td>\n",
       "      <td>2.287445</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.041341</td>\n",
       "      <td>2.383582</td>\n",
       "      <td>-0.417253</td>\n",
       "      <td>1.305379</td>\n",
       "      <td>-0.435123</td>\n",
       "      <td>-0.468557</td>\n",
       "      <td>0.923290</td>\n",
       "      <td>3.880050</td>\n",
       "      <td>2.676798</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.454974</td>\n",
       "      <td>1.293300</td>\n",
       "      <td>0.112201</td>\n",
       "      <td>-0.589989</td>\n",
       "      <td>-1.674321</td>\n",
       "      <td>1.293300</td>\n",
       "      <td>0.487302</td>\n",
       "      <td>1.776318</td>\n",
       "      <td>0.702520</td>\n",
       "      <td>-1.024127</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.452869</td>\n",
       "      <td>-0.667306</td>\n",
       "      <td>0.345364</td>\n",
       "      <td>-3.920591</td>\n",
       "      <td>-0.438296</td>\n",
       "      <td>-1.690141</td>\n",
       "      <td>0.176906</td>\n",
       "      <td>1.920142</td>\n",
       "      <td>1.474634</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       var0      var1      var2      var3      var4      var5      var6  \\\n",
       "0 -2.882513 -3.272465 -2.520732 -1.987174 -2.073689 -3.272465 -1.237969   \n",
       "1  0.775242 -1.015994  0.005137  0.057274  0.590205 -1.015994  1.350954   \n",
       "2 -0.876376  0.220453  3.114224 -1.640025  1.180348  0.220453  0.465102   \n",
       "3 -2.550342 -1.968144  0.077681 -1.887719  1.864445 -1.968144 -0.527958   \n",
       "4 -0.454974  1.293300  0.112201 -0.589989 -1.674321  1.293300  0.487302   \n",
       "\n",
       "       var7      var8      var9  ...     var11     var12     var13     var14  \\\n",
       "0  1.690547 -0.211314 -5.753190  ... -0.574979 -1.916275 -5.994075 -3.349615   \n",
       "1 -1.493037 -0.862391 -1.986047  ...  0.523760  0.399579  0.088600  0.718606   \n",
       "2  0.222511  0.880455  2.922315  ... -0.370516  3.585262 -2.168162  2.693429   \n",
       "3 -0.201467 -0.532649  2.287445  ... -0.041341  2.383582 -0.417253  1.305379   \n",
       "4  1.776318  0.702520 -1.024127  ... -0.452869 -0.667306  0.345364 -3.920591   \n",
       "\n",
       "      var15     var16     var17     var18     var19  target  \n",
       "0 -0.846193  2.491347  1.360958 -2.892522 -1.377561     0.0  \n",
       "1 -1.112030  0.083929  0.606544 -1.376793  1.302641     2.0  \n",
       "2 -0.966636  1.586302 -2.821546  0.482164  0.187404     0.0  \n",
       "3 -0.435123 -0.468557  0.923290  3.880050  2.676798     1.0  \n",
       "4 -0.438296 -1.690141  0.176906  1.920142  1.474634     0.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('pca-dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1500 entries, 0 to 1499\n",
      "Data columns (total 21 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   var0    1500 non-null   float64\n",
      " 1   var1    1500 non-null   float64\n",
      " 2   var2    1500 non-null   float64\n",
      " 3   var3    1500 non-null   float64\n",
      " 4   var4    1500 non-null   float64\n",
      " 5   var5    1500 non-null   float64\n",
      " 6   var6    1500 non-null   float64\n",
      " 7   var7    1500 non-null   float64\n",
      " 8   var8    1500 non-null   float64\n",
      " 9   var9    1500 non-null   float64\n",
      " 10  var10   1500 non-null   float64\n",
      " 11  var11   1500 non-null   float64\n",
      " 12  var12   1500 non-null   float64\n",
      " 13  var13   1500 non-null   float64\n",
      " 14  var14   1500 non-null   float64\n",
      " 15  var15   1500 non-null   float64\n",
      " 16  var16   1500 non-null   float64\n",
      " 17  var17   1500 non-null   float64\n",
      " 18  var18   1500 non-null   float64\n",
      " 19  var19   1500 non-null   float64\n",
      " 20  target  1500 non-null   float64\n",
      "dtypes: float64(21)\n",
      "memory usage: 246.2 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 1,200\n",
      "Test samples: 300\n",
      "\n",
      "Features:\n",
      "var0\tvar1\tvar2\tvar3\tvar4\tvar5\tvar6\tvar7\tvar8\tvar9\tvar10\tvar11\tvar12\tvar13\tvar14\tvar15\tvar16\tvar17\tvar18\tvar19\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df[[x for x in df.columns if x.startswith('var')]]\n",
    "y = df['target']\n",
    "\n",
    "X_train, X_test, y_training, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "print(f'Training samples: {X_train.shape[0]:,}')\n",
    "print(f'Test samples: {X_test.shape[0]:,}')\n",
    "\n",
    "print('\\nFeatures:')\n",
    "print(*X_train, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Description\n",
    "- `var1 - var19`: a feature for the data.  \n",
    "- `target`: variable we wish to be able to predict, which is 1 of 3 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 2., 1.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.target.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "- Use principle components analysis to determine the number of components to reduce the data to by evaluating the explained variance ratio (use `X_train`).  \n",
    "- Remember to scale the data first.  \n",
    "- What number of components would you recommend based on your analysis?  \n",
    "- Explain your results using markdown cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>PCA()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "PCA()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  -0.1  0.1  0.  -0.2 -0.1  0.1  0.  -0.1 -0.  -0.   0.1 -0.3  0.5\n",
      "   0.5 -0.4 -0.3  0.   0.2  0.3]\n",
      " [-0.1  1.   0.   0.1  0.1  1.  -0.  -0.   0.   0.1 -0.   0.   0.4  0.1\n",
      "  -0.6  0.   0.  -0.  -0.3  0.1]\n",
      " [ 0.1  0.   1.   0.1 -0.1  0.   0.  -0.  -0.   0.1 -0.  -0.   0.3 -0.2\n",
      "   0.3 -0.   0.2  0.  -0.1  0.1]\n",
      " [ 0.   0.1  0.1  1.   0.1  0.1 -0.   0.   0.  -0.1  0.   0.  -0.1  0.6\n",
      "   0.1  0.8 -0.1 -0.  -0.2  0. ]\n",
      " [-0.2  0.1 -0.1  0.1  1.   0.1  0.   0.   0.1  0.1 -0.  -0.   0.7  0.\n",
      "   0.3 -0.1  0.3 -0.1 -0.6 -0.2]\n",
      " [-0.1  1.   0.   0.1  0.1  1.  -0.  -0.   0.   0.1 -0.   0.   0.4  0.1\n",
      "  -0.6  0.   0.  -0.  -0.3  0.1]\n",
      " [ 0.1 -0.   0.  -0.   0.  -0.   1.   0.  -0.   0.  -0.   0.  -0.   0.\n",
      "   0.  -0.1 -0.   0.   0.  -0. ]\n",
      " [ 0.  -0.  -0.   0.   0.  -0.   0.   1.   0.1  0.  -0.   0.  -0.   0.1\n",
      "   0.1  0.  -0.  -0.   0.   0. ]\n",
      " [-0.1  0.  -0.   0.   0.1  0.  -0.   0.1  1.   0.   0.   0.   0.1 -0.\n",
      "  -0.   0.   0.1 -0.  -0.1 -0. ]\n",
      " [-0.   0.1  0.1 -0.1  0.1  0.1  0.   0.   0.   1.  -0.  -0.   0.   0.2\n",
      "   0.3  0.2 -0.1  0.   0.5 -0. ]\n",
      " [-0.  -0.  -0.   0.  -0.  -0.  -0.  -0.   0.  -0.   1.   0.  -0.  -0.\n",
      "   0.   0.   0.   0.1 -0.   0. ]\n",
      " [ 0.1  0.  -0.   0.  -0.   0.   0.   0.   0.  -0.   0.   1.   0.   0.\n",
      "   0.  -0.  -0.   0.  -0.   0. ]\n",
      " [-0.3  0.4  0.3 -0.1  0.7  0.4 -0.  -0.   0.1  0.  -0.   0.   1.  -0.5\n",
      "   0.1 -0.2  0.7 -0.  -0.7  0.1]\n",
      " [ 0.5  0.1 -0.2  0.6  0.   0.1  0.   0.1 -0.   0.2 -0.   0.  -0.5  1.\n",
      "   0.   0.3 -0.8  0.   0.3  0.2]\n",
      " [ 0.5 -0.6  0.3  0.1  0.3 -0.6  0.   0.1 -0.   0.3  0.   0.   0.1  0.\n",
      "   1.  -0.1  0.3 -0.   0.   0. ]\n",
      " [-0.4  0.  -0.   0.8 -0.1  0.  -0.1  0.   0.   0.2  0.  -0.  -0.2  0.3\n",
      "  -0.1  1.   0.1  0.   0.  -0.1]\n",
      " [-0.3  0.   0.2 -0.1  0.3  0.  -0.  -0.   0.1 -0.1  0.  -0.   0.7 -0.8\n",
      "   0.3  0.1  1.  -0.  -0.6 -0.1]\n",
      " [ 0.  -0.   0.  -0.  -0.1 -0.   0.  -0.  -0.   0.   0.1  0.  -0.   0.\n",
      "  -0.   0.  -0.   1.   0.1  0.1]\n",
      " [ 0.2 -0.3 -0.1 -0.2 -0.6 -0.3  0.   0.  -0.1  0.5 -0.  -0.  -0.7  0.3\n",
      "   0.   0.  -0.6  0.1  1.   0.3]\n",
      " [ 0.3  0.1  0.1  0.  -0.2  0.1 -0.   0.  -0.  -0.   0.   0.   0.1  0.2\n",
      "   0.  -0.1 -0.1  0.1  0.3  1. ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "cov_mat = np.cov(X_train_scaled.T)\n",
    "print(cov_mat.round(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wihar\\anaconda3\\lib\\site-packages\\matplotlib\\cbook\\__init__.py:1335: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  return np.asarray(x, float)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eigen_vals, eigen_vecs = np.linalg.eig(cov_mat)\n",
    "\n",
    "plt.plot(eigen_vals)\n",
    "plt.title('Eigenvalues', loc='left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Based on this plot, we can see that the first 13 components explain the majority of the variance in the data. Therefore, we could consider reducing the data to these 13 components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "- Evaluate the target variable in the `df` object.  \n",
    "- Which metric would you use in evaluating a predictive model. Explain your choice in the markdown cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    744\n",
       "2.0    380\n",
       "1.0    376\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This tells us that the dataset is roughly balanced, with 2 class having a similar number of samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Since the target variable in this dataset is categorical with three classes, we are dealing with a multi-class classification problem.\n",
    "    - Accuracy can be misleading when the classes are imbalanced\n",
    "    - Precision, recall, and F1 score metrics are commonly used in multi-class classification and take into account the number of true positives, false positives, and false negatives. \n",
    "    - Confusion matrix: This is a table that summarizes the number of correct and incorrect predictions for each class. It can be used to calculate other evaluation metrics such as precision, recall, and F1 score.\n",
    "- Since the classes are imbalanced, it would be advisable to use a metric that takes into account both precision and recall, such as the F1 score or the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.70\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_scaled, y_training)\n",
    "y_pred = lr.predict(X_test_scaled)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(f'F1 score: {f1:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "- Without using PCA, create a logistic regression model using practices discussed in class.  \n",
    "- Which model would you choose? Explain your results in the markdown cells.    \n",
    "- What is the accuracy, precision, and recall for the test data?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.703\n",
      "Precision: 0.704\n",
      "Recall: 0.703\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "clf = LogisticRegression()\n",
    "\n",
    "# fit the model to the training data\n",
    "clf.fit(X_train, y_training)\n",
    "\n",
    "# predict on the test data\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f'Accuracy: {accuracy:.3f}')\n",
    "print(f'Precision: {precision:.3f}')\n",
    "print(f'Recall: {recall:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The accuracy of the model is 0.803, which means that the model correctly predicted 80.3% of the instances in the test data.\n",
    "\n",
    "- The precision of the model is 0.804, which means that when the model predicts a sample as positive, it is correct 80.4% of the time.\n",
    "\n",
    "- The recall of the model is 0.803, which means that the model correctly identifies 80.3% of the positive samples in the test data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Both PCA model and Logistic regression model produced the same accuracy.<br/>\n",
    "The performance of the logistic regression model could potentially be improved by feature engineering, feature selection, or parameter tuning. Hence I would select Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "- Use PCA within a pipeline to create a logistic regression model using best practices from class.  \n",
    "- Which model performs the best on the training data? Explain your results in markdown cells.  \n",
    "- What is the accuracy, precision, and recall for the test data?\n",
    "- Does this perform better than the original logistic regression model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaling&#x27;, StandardScaler()), (&#x27;pca&#x27;, PCA()),\n",
       "                (&#x27;model&#x27;, LogisticRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaling&#x27;, StandardScaler()), (&#x27;pca&#x27;, PCA()),\n",
       "                (&#x27;model&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scaling', StandardScaler()), ('pca', PCA()),\n",
       "                ('model', LogisticRegression())])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "p = Pipeline([('scaling', StandardScaler()), \n",
    "              ('pca', PCA()),\n",
    "              ('model', LogisticRegression())\n",
    "             ])\n",
    "\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.703\n",
      "Precision: 0.704\n",
      "Recall: 0.703\n",
      "F1 Score: 0.703\n"
     ]
    }
   ],
   "source": [
    "p.fit(X_train, y_training)\n",
    "y_pred = p.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "print(f\"Recall: {recall:.3f}\")\n",
    "print(f\"F1 Score: {f1:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Even with using PCA the Scores is same hence using PCA did not improved accuracy in this case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Without using PCA, create a decision tree model using best practices discussed in class.  \n",
    "- Which model performs the best on the training data? Explain your results in the markdown cells.  \n",
    "- What is the accuracy, precision, and recall for the test data?  \n",
    "- Does this perform better than either of the logistic regression models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;decisiontreeclassifier&#x27;, DecisionTreeClassifier())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;decisiontreeclassifier&#x27;, DecisionTreeClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('decisiontreeclassifier', DecisionTreeClassifier())])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.tree  import DecisionTreeClassifier\n",
    "\n",
    "p = make_pipeline(StandardScaler(), DecisionTreeClassifier())\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.673\n",
      "Precision: 0.690\n",
      "Recall: 0.673\n",
      "F1 Score: 0.678\n"
     ]
    }
   ],
   "source": [
    "p.fit(X_train, y_training)\n",
    "y_pred = p.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "print(f\"Recall: {recall:.3f}\")\n",
    "print(f\"F1 Score: {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Decision Tree Clasifier reduced the scores Hence it is not the best model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6\n",
    "- Repeat `Question 5` but use PCA.  \n",
    "- Does this perform better than the original Decision Tree or the logistic regression models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_dt_pca = Pipeline([('scaling', StandardScaler()),\n",
    "                        ('pca', PCA(n_components=10)),\n",
    "                        ('dt', DecisionTreeClassifier())])\n",
    "\n",
    "\n",
    "pipe_dt_pca.fit(X_train, y_training)\n",
    "\n",
    "y_pred_dt_pca = pipe_dt_pca.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.673\n",
      "Precision: 0.690\n",
      "Recall: 0.673\n",
      "F1 Score: 0.678\n"
     ]
    }
   ],
   "source": [
    "acc_dt_pca = accuracy_score(y_test, y_pred_dt_pca)\n",
    "prec_dt_pca = precision_score(y_test, y_pred_dt_pca, average='weighted')\n",
    "rec_dt_pca = recall_score(y_test, y_pred_dt_pca, average='weighted')\n",
    "f1_dt_pca = f1_score(y_test, y_pred_dt_pca, average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "print(f\"Recall: {recall:.3f}\")\n",
    "print(f\"F1 Score: {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Even with PCA decision tree Classifier didnot perfrom greatly then Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
